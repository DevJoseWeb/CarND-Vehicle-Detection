{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as mpimg\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# import glob\n",
    "\n",
    "# # Define a function to compute binned color features  \n",
    "# def bin_spatial(img, c_space='RGB', size=(32, 32)):\n",
    "#     if c_space != 'RGB':\n",
    "#         if c_space == 'HSV':\n",
    "#             feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "#         elif c_space == 'LUV':\n",
    "#             feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2LUV)\n",
    "#         elif c_space == 'HLS':\n",
    "#             feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "#         elif c_space == 'YUV':\n",
    "#             feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "#     else: \n",
    "#         feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)      \n",
    "\n",
    "#     # Use cv2.resize().ravel() to create the feature vector\n",
    "#     features = cv2.resize(feature_image, size).ravel() \n",
    "#     # Return the feature vector\n",
    "#     return feature_image, features\n",
    "\n",
    "# # Define a function to compute color histogram features  \n",
    "# def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "#     # Compute the histogram of the color channels separately\n",
    "#     channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "#     channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "#     channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "#     # Concatenate the histograms into a single feature vector\n",
    "#     hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "#     # Return the individual histograms, bin_centers and feature vector\n",
    "#     return hist_features\n",
    "\n",
    "# ###### TODO ###########\n",
    "# # Define a function to extract features from a list of images\n",
    "# # Have this function call bin_spatial() and color_hist()\n",
    "# def extract_features(imgs, cspace='RGB', spatial_size=(32, 32),\n",
    "#                         hist_bins=32, hist_range=(0, 256)):\n",
    "#     # Create a list to append feature vectors to\n",
    "#     features = []\n",
    "#     # Iterate through the list of images\n",
    "#     for i in imgs:\n",
    "#         # Read in each one by one\n",
    "#         image = cv2.imread(i)\n",
    "#         # apply color conversion if other than 'RGB'\n",
    "#         # Apply bin_spatial() to get spatial color features\n",
    "#         feature_image, spatial_features = bin_spatial(image, c_space=cspace, size=spatial_size)\n",
    "#         # Apply color_hist() to get color histogram features\n",
    "#         hist_features = color_hist(feature_image, hist_bins, hist_range)\n",
    "#         # Append the new feature vector to the features list\n",
    "#         features.append(np.concatenate((spatial_features, hist_features)))\n",
    "#     # Return list of feature vectors\n",
    "#     return features\n",
    "\n",
    "# images = glob.glob('*.jpeg')\n",
    "# cars = []\n",
    "# notcars = []\n",
    "# for image in images:\n",
    "#     if 'image' in image or 'extra' in image:\n",
    "#         notcars.append(image)\n",
    "#     else:\n",
    "#         cars.append(image)\n",
    "        \n",
    "# car_features = extract_features(cars, cspace='RGB', spatial_size=(32, 32),\n",
    "#                         hist_bins=32, hist_range=(0, 256))\n",
    "# notcar_features = extract_features(notcars, cspace='RGB', spatial_size=(32, 32),\n",
    "#                         hist_bins=32, hist_range=(0, 256))\n",
    "\n",
    "# if len(car_features) > 0:\n",
    "#     # Create an array stack of feature vectors\n",
    "#     X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "#     # Fit a per-column scaler\n",
    "#     X_scaler = StandardScaler().fit(X)\n",
    "#     # Apply the scaler to X\n",
    "#     scaled_X = X_scaler.transform(X)\n",
    "#     car_ind = np.random.randint(0, len(cars))\n",
    "#     # Plot an example of raw and scaled features\n",
    "#     fig = plt.figure(figsize=(12,4))\n",
    "#     plt.subplot(131)\n",
    "#     plt.imshow(mpimg.imread(cars[car_ind]))\n",
    "#     plt.title('Original Image')\n",
    "#     plt.subplot(132)\n",
    "#     plt.plot(X[car_ind])\n",
    "#     plt.title('Raw Features')\n",
    "#     plt.subplot(133)\n",
    "#     plt.plot(scaled_X[car_ind])\n",
    "#     plt.title('Normalized Features')\n",
    "#     fig.tight_layout()\n",
    "# else: \n",
    "#     print('Your function only returns empty feature vectors...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All together now -- normalization \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as mpimg\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# import glob\n",
    "\n",
    "# # Define a function to compute binned color features  \n",
    "# def bin_spatial(img, c_space='RGB', size=(32, 32)):\n",
    "#     if c_space != 'RGB':\n",
    "#         if c_space == 'HSV':\n",
    "#             feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "#         elif c_space == 'LUV':\n",
    "#             feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2LUV)\n",
    "#         elif c_space == 'HLS':\n",
    "#             feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "#         elif c_space == 'YUV':\n",
    "#             feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "#     else: \n",
    "#         feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)      \n",
    "\n",
    "#     # Use cv2.resize().ravel() to create the feature vector\n",
    "#     features = cv2.resize(feature_image, size).ravel() \n",
    "#     # Return the feature vector\n",
    "#     return feature_image, features\n",
    "\n",
    "# # Define a function to compute color histogram features  \n",
    "# def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "#     # Compute the histogram of the color channels separately\n",
    "#     channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "#     channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "#     channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "#     # Concatenate the histograms into a single feature vector\n",
    "#     hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "#     # Return the individual histograms, bin_centers and feature vector\n",
    "#     return hist_features\n",
    "\n",
    "# ###### TODO ###########\n",
    "# # Define a function to extract features from a list of images\n",
    "# # Have this function call bin_spatial() and color_hist()\n",
    "# def extract_features(imgs, cspace='RGB', spatial_size=(32, 32),\n",
    "#                         hist_bins=32, hist_range=(0, 256)):\n",
    "#     # Create a list to append feature vectors to\n",
    "#     features = []\n",
    "#     # Iterate through the list of images\n",
    "#     for i in imgs:\n",
    "#         # Read in each one by one\n",
    "#         image = cv2.imread(i)\n",
    "#         # apply color conversion if other than 'RGB'\n",
    "#         # Apply bin_spatial() to get spatial color features\n",
    "#         feature_image, spatial_features = bin_spatial(image, c_space=cspace, size=spatial_size)\n",
    "#         # Apply color_hist() to get color histogram features\n",
    "#         hist_features = color_hist(feature_image, hist_bins, hist_range)\n",
    "#         # Append the new feature vector to the features list\n",
    "#         features.append(np.concatenate((spatial_features, hist_features)))\n",
    "#     # Return list of feature vectors\n",
    "#     return features\n",
    "\n",
    "# images = glob.glob('*.jpeg')\n",
    "# cars = []\n",
    "# notcars = []\n",
    "# for image in images:\n",
    "#     if 'image' in image or 'extra' in image:\n",
    "#         notcars.append(image)\n",
    "#     else:\n",
    "#         cars.append(image)\n",
    "        \n",
    "# car_features = extract_features(cars, cspace='RGB', spatial_size=(32, 32),\n",
    "#                         hist_bins=32, hist_range=(0, 256))\n",
    "# notcar_features = extract_features(notcars, cspace='RGB', spatial_size=(32, 32),\n",
    "#                         hist_bins=32, hist_range=(0, 256))\n",
    "\n",
    "# if len(car_features) > 0:\n",
    "#     # Create an array stack of feature vectors\n",
    "#     X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "#     # Fit a per-column scaler\n",
    "#     X_scaler = StandardScaler().fit(X)\n",
    "#     # Apply the scaler to X\n",
    "#     scaled_X = X_scaler.transform(X)\n",
    "#     car_ind = np.random.randint(0, len(cars))\n",
    "#     # Plot an example of raw and scaled features\n",
    "#     fig = plt.figure(figsize=(12,4))\n",
    "#     plt.subplot(131)\n",
    "#     plt.imshow(mpimg.imread(cars[car_ind]))\n",
    "#     plt.title('Original Image')\n",
    "#     plt.subplot(132)\n",
    "#     plt.plot(X[car_ind])\n",
    "#     plt.title('Raw Features')\n",
    "#     plt.subplot(133)\n",
    "#     plt.plot(scaled_X[car_ind])\n",
    "#     plt.title('Normalized Features')\n",
    "#     fig.tight_layout()\n",
    "# else: \n",
    "#     print('Your function only returns empty feature vectors...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.image as mpimg\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "# import glob\n",
    "# import time\n",
    "# from sklearn.svm import LinearSVC\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# # NOTE: the next import is only valid \n",
    "# # for scikit-learn version <= 0.17\n",
    "# # if you are using scikit-learn >= 0.18 then use this:\n",
    "# # from sklearn.model_selection import train_test_split\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# # Define a function to compute binned color features  \n",
    "# def bin_spatial(img, size=(32, 32)):\n",
    "#     # Use cv2.resize().ravel() to create the feature vector\n",
    "#     features = cv2.resize(img, size).ravel() \n",
    "#     # Return the feature vector\n",
    "#     return features\n",
    "\n",
    "# # Define a function to compute color histogram features  \n",
    "# def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "#     # Compute the histogram of the color channels separately\n",
    "#     channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "#     channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "#     channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "#     # Concatenate the histograms into a single feature vector\n",
    "#     hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "#     # Return the individual histograms, bin_centers and feature vector\n",
    "#     return hist_features\n",
    "\n",
    "# # Define a function to extract features from a list of images\n",
    "# # Have this function call bin_spatial() and color_hist()\n",
    "# def extract_features(imgs, cspace='RGB', spatial_size=(32, 32),\n",
    "#                         hist_bins=32, hist_range=(0, 256)):\n",
    "#     # Create a list to append feature vectors to\n",
    "#     features = []\n",
    "#     # Iterate through the list of images\n",
    "#     for file in imgs:\n",
    "#         # Read in each one by one\n",
    "#         image = mpimg.imread(file)\n",
    "#         # apply color conversion if other than 'RGB'\n",
    "#         if cspace != 'RGB':\n",
    "#             if cspace == 'HSV':\n",
    "#                 feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "#             elif cspace == 'LUV':\n",
    "#                 feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "#             elif cspace == 'HLS':\n",
    "#                 feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "#             elif cspace == 'YUV':\n",
    "#                 feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "#         else: feature_image = np.copy(image)      \n",
    "#         # Apply bin_spatial() to get spatial color features\n",
    "#         spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "#         # Apply color_hist() also with a color space option now\n",
    "#         hist_features = color_hist(feature_image, nbins=hist_bins, bins_range=hist_range)\n",
    "#         # Append the new feature vector to the features list\n",
    "#         features.append(np.concatenate((spatial_features, hist_features)))\n",
    "#     # Return list of feature vectors\n",
    "#     return features\n",
    "\n",
    "\n",
    "# # Read in car and non-car images\n",
    "# images = glob.glob('*.jpeg')\n",
    "# cars = []\n",
    "# notcars = []\n",
    "# for image in images:\n",
    "#     if 'image' in image or 'extra' in image:\n",
    "#         notcars.append(image)\n",
    "#     else:\n",
    "#         cars.append(image)\n",
    "\n",
    "# # TODO play with these values to see how your classifier\n",
    "# # performs under different binning scenarios\n",
    "# spatial = 32\n",
    "# histbin = 32\n",
    "\n",
    "# car_features = extract_features(cars, cspace='RGB', spatial_size=(spatial, spatial),\n",
    "#                         hist_bins=histbin, hist_range=(0, 256))\n",
    "# notcar_features = extract_features(notcars, cspace='RGB', spatial_size=(spatial, spatial),\n",
    "#                         hist_bins=histbin, hist_range=(0, 256))\n",
    "\n",
    "# # Create an array stack of feature vectors\n",
    "# X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "# # Fit a per-column scaler\n",
    "# X_scaler = StandardScaler().fit(X)\n",
    "# # Apply the scaler to X\n",
    "# scaled_X = X_scaler.transform(X)\n",
    "\n",
    "# # Define the labels vector\n",
    "# y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "\n",
    "# # Split up data into randomized training and test sets\n",
    "# rand_state = np.random.randint(0, 100)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "# print('Using spatial binning of:',spatial,\n",
    "#     'and', histbin,'histogram bins')\n",
    "# print('Feature vector length:', len(X_train[0]))\n",
    "# # Use a linear SVC \n",
    "# svc = LinearSVC()\n",
    "# # Check the training time for the SVC\n",
    "# t=time.time()\n",
    "# svc.fit(X_train, y_train)\n",
    "# t2 = time.time()\n",
    "# print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "# # Check the score of the SVC\n",
    "# print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "# # Check the prediction time for a single sample\n",
    "# t=time.time()\n",
    "# n_predict = 10\n",
    "# print('My SVC predicts: ', svc.predict(X_test[0:n_predict]))\n",
    "# print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "# t2 = time.time()\n",
    "# print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOG Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.image as mpimg\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "# import glob\n",
    "# import time\n",
    "# from sklearn.svm import LinearSVC\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from skimage.feature import hog\n",
    "# # NOTE: the next import is only valid for scikit-learn version <= 0.17\n",
    "# # for scikit-learn >= 0.18 use:\n",
    "# # from sklearn.model_selection import train_test_split\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# # Define a function to return HOG features and visualization\n",
    "# def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "#                         vis=False, feature_vec=True):\n",
    "#     # Call with two outputs if vis==True\n",
    "#     if vis == True:\n",
    "#         features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "#                                   cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=True, \n",
    "#                                   visualise=vis, feature_vector=feature_vec)\n",
    "#         return features, hog_image\n",
    "#     # Otherwise call with one output\n",
    "#     else:      \n",
    "#         features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "#                        cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=True, \n",
    "#                        visualise=vis, feature_vector=feature_vec)\n",
    "#         return features\n",
    "\n",
    "# # Define a function to extract features from a list of images\n",
    "# # Have this function call bin_spatial() and color_hist()\n",
    "# def extract_features(imgs, cspace='RGB', orient=9, \n",
    "#                         pix_per_cell=8, cell_per_block=2, hog_channel=0):\n",
    "#     # Create a list to append feature vectors to\n",
    "#     features = []\n",
    "#     # Iterate through the list of images\n",
    "#     for file in imgs:\n",
    "#         # Read in each one by one\n",
    "#         image = mpimg.imread(file)\n",
    "#         # apply color conversion if other than 'RGB'\n",
    "#         if cspace != 'RGB':\n",
    "#             if cspace == 'HSV':\n",
    "#                 feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "#             elif cspace == 'LUV':\n",
    "#                 feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "#             elif cspace == 'HLS':\n",
    "#                 feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "#             elif cspace == 'YUV':\n",
    "#                 feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "#             elif cspace == 'YCrCb':\n",
    "#                 feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "#         else: feature_image = np.copy(image)      \n",
    "\n",
    "#         # Call get_hog_features() with vis=False, feature_vec=True\n",
    "#         if hog_channel == 'ALL':\n",
    "#             hog_features = []\n",
    "#             for channel in range(feature_image.shape[2]):\n",
    "#                 hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
    "#                                     orient, pix_per_cell, cell_per_block, \n",
    "#                                     vis=False, feature_vec=True))\n",
    "#             hog_features = np.ravel(hog_features)        \n",
    "#         else:\n",
    "#             hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "#                         pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "#         # Append the new feature vector to the features list\n",
    "#         features.append(hog_features)\n",
    "#     # Return list of feature vectors\n",
    "#     return features\n",
    "\n",
    "\n",
    "# # Divide up into cars and notcars\n",
    "# images = glob.glob('*.jpeg')\n",
    "# cars = []\n",
    "# notcars = []\n",
    "# for image in images:\n",
    "#     if 'image' in image or 'extra' in image:\n",
    "#         notcars.append(image)\n",
    "#     else:\n",
    "#         cars.append(image)\n",
    "\n",
    "# # Reduce the sample size because HOG features are slow to compute\n",
    "# # The quiz evaluator times out after 13s of CPU time\n",
    "# sample_size = 500\n",
    "# cars = cars[0:sample_size]\n",
    "# notcars = notcars[0:sample_size]\n",
    "\n",
    "# ### TODO: Tweak these parameters and see how the results change.\n",
    "# colorspace = 'LUV' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "# orient = 8\n",
    "# pix_per_cell = 8\n",
    "# cell_per_block = 4\n",
    "# hog_channel = \"ALL\" # Can be 0, 1, 2, or \"ALL\"\n",
    "\n",
    "# t=time.time()\n",
    "# car_features = extract_features(cars, cspace=colorspace, orient=orient, \n",
    "#                         pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "#                         hog_channel=hog_channel)\n",
    "# notcar_features = extract_features(notcars, cspace=colorspace, orient=orient, \n",
    "#                         pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "#                         hog_channel=hog_channel)\n",
    "# t2 = time.time()\n",
    "# print(round(t2-t, 2), 'Seconds to extract HOG features...')\n",
    "# # Create an array stack of feature vectors\n",
    "# X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "# # Fit a per-column scaler\n",
    "# X_scaler = StandardScaler().fit(X)\n",
    "# # Apply the scaler to X\n",
    "# scaled_X = X_scaler.transform(X)\n",
    "\n",
    "# # Define the labels vector\n",
    "# y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "\n",
    "# # Split up data into randomized training and test sets\n",
    "# rand_state = np.random.randint(0, 100)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "# print('Using:',orient,'orientations',pix_per_cell,\n",
    "#     'pixels per cell and', cell_per_block,'cells per block')\n",
    "# print('Feature vector length:', len(X_train[0]))\n",
    "# # Use a linear SVC \n",
    "# svc = LinearSVC()\n",
    "# # Check the training time for the SVC\n",
    "# t=time.time()\n",
    "# svc.fit(X_train, y_train)\n",
    "# t2 = time.time()\n",
    "# print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "# # Check the score of the SVC\n",
    "# print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "# # Check the prediction time for a single sample\n",
    "# t=time.time()\n",
    "# n_predict = 10\n",
    "# print('My SVC predicts: ', svc.predict(X_test[0:n_predict]))\n",
    "# print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "# t2 = time.time()\n",
    "# print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial, Hist, and HOG Combined Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.image as mpimg\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "# import glob\n",
    "# import time\n",
    "# from sklearn.svm import LinearSVC\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from skimage.feature import hog\n",
    "# from lesson_functions import *\n",
    "# # NOTE: the next import is only valid for scikit-learn version <= 0.17\n",
    "# # for scikit-learn >= 0.18 use:\n",
    "# # from sklearn.model_selection import train_test_split\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# # Define a function to extract features from a single image window\n",
    "# # This function is very similar to extract_features()\n",
    "# # just for a single image rather than list of images\n",
    "# def single_img_features(img, color_space='RGB', spatial_size=(32, 32),\n",
    "#                         hist_bins=32, orient=9, \n",
    "#                         pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "#                         spatial_feat=True, hist_feat=True, hog_feat=True):    \n",
    "#     #1) Define an empty list to receive features\n",
    "#     img_features = []\n",
    "#     #2) Apply color conversion if other than 'RGB'\n",
    "#     if color_space != 'RGB':\n",
    "#         if color_space == 'HSV':\n",
    "#             feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "#         elif color_space == 'LUV':\n",
    "#             feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "#         elif color_space == 'HLS':\n",
    "#             feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "#         elif color_space == 'YUV':\n",
    "#             feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "#         elif color_space == 'YCrCb':\n",
    "#             feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "#     else: feature_image = np.copy(img)      \n",
    "#     #3) Compute spatial features if flag is set\n",
    "#     if spatial_feat == True:\n",
    "#         spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "#         #4) Append features to list\n",
    "#         img_features.append(spatial_features)\n",
    "#     #5) Compute histogram features if flag is set\n",
    "#     if hist_feat == True:\n",
    "#         hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "#         #6) Append features to list\n",
    "#         img_features.append(hist_features)\n",
    "#     #7) Compute HOG features if flag is set\n",
    "#     if hog_feat == True:\n",
    "#         if hog_channel == 'ALL':\n",
    "#             hog_features = []\n",
    "#             for channel in range(feature_image.shape[2]):\n",
    "#                 hog_features.extend(get_hog_features(feature_image[:,:,channel], \n",
    "#                                     orient, pix_per_cell, cell_per_block, \n",
    "#                                     vis=False, feature_vec=True))      \n",
    "#         else:\n",
    "#             hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "#                         pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "#         #8) Append features to list\n",
    "#         img_features.append(hog_features)\n",
    "\n",
    "#     #9) Return concatenated array of features\n",
    "#     return np.concatenate(img_features)\n",
    "\n",
    "# # Define a function you will pass an image \n",
    "# # and the list of windows to be searched (output of slide_windows())\n",
    "# def search_windows(img, windows, clf, scaler, color_space='RGB', \n",
    "#                     spatial_size=(32, 32), hist_bins=32, \n",
    "#                     hist_range=(0, 256), orient=9, \n",
    "#                     pix_per_cell=8, cell_per_block=2, \n",
    "#                     hog_channel=0, spatial_feat=True, \n",
    "#                     hist_feat=True, hog_feat=True):\n",
    "\n",
    "#     #1) Create an empty list to receive positive detection windows\n",
    "#     on_windows = []\n",
    "#     #2) Iterate over all windows in the list\n",
    "#     for window in windows:\n",
    "#         #3) Extract the test window from original image\n",
    "#         test_img = cv2.resize(img[window[0][1]:window[1][1], window[0][0]:window[1][0]], (64, 64))      \n",
    "#         #4) Extract features for that window using single_img_features()\n",
    "#         features = single_img_features(test_img, color_space=color_space, \n",
    "#                             spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "#                             orient=orient, pix_per_cell=pix_per_cell, \n",
    "#                             cell_per_block=cell_per_block, \n",
    "#                             hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "#                             hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "#         #5) Scale extracted features to be fed to classifier\n",
    "#         test_features = scaler.transform(np.array(features).reshape(1, -1))\n",
    "#         #6) Predict using your classifier\n",
    "#         prediction = clf.predict(test_features)\n",
    "#         #7) If positive (prediction == 1) then save the window\n",
    "#         if prediction == 1:\n",
    "#             on_windows.append(window)\n",
    "#     #8) Return windows for positive detections\n",
    "#     return on_windows\n",
    "    \n",
    "    \n",
    "# # Read in cars and notcars\n",
    "# images = glob.glob('*.jpeg')\n",
    "# cars = []\n",
    "# notcars = []\n",
    "# for image in images:\n",
    "#     if 'image' in image or 'extra' in image:\n",
    "#         notcars.append(image)\n",
    "#     else:\n",
    "#         cars.append(image)\n",
    "\n",
    "# # Reduce the sample size because\n",
    "# # The quiz evaluator times out after 13s of CPU time\n",
    "# sample_size = 500\n",
    "# cars = cars[0:sample_size]\n",
    "# notcars = notcars[0:sample_size]\n",
    "\n",
    "# ### TODO: Tweak these parameters and see how the results change.\n",
    "# image = mpimg.imread('bbox-example-image.jpg')\n",
    "# image_shape = (image.shape[1], image.shape[0])\n",
    "# color_space = 'LUV' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "# orient = 9  # HOG orientations\n",
    "# pix_per_cell = 8 # HOG pixels per cell\n",
    "# cell_per_block = 4 # HOG cells per block\n",
    "# hog_channel = \"ALL\" # Can be 0, 1, 2, or \"ALL\"\n",
    "# spatial_size = (8, 8) # Spatial binning dimensions\n",
    "# hist_bins = 32    # Number of histogram bins\n",
    "# spatial_feat = True # Spatial features on or off\n",
    "# hist_feat = False # Histogram features on or off\n",
    "# hog_feat = True # HOG features on or off\n",
    "# y_start_stop = [None, None] # Min and max in y to search in slide_window()\n",
    "\n",
    "# car_features = extract_features(cars, color_space=color_space, \n",
    "#                         spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "#                         orient=orient, pix_per_cell=pix_per_cell, \n",
    "#                         cell_per_block=cell_per_block, \n",
    "#                         hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "#                         hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "# notcar_features = extract_features(notcars, color_space=color_space, \n",
    "#                         spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "#                         orient=orient, pix_per_cell=pix_per_cell, \n",
    "#                         cell_per_block=cell_per_block, \n",
    "#                         hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "#                         hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "\n",
    "# X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "# # Fit a per-column scaler\n",
    "# X_scaler = StandardScaler().fit(X)\n",
    "# # Apply the scaler to X\n",
    "# scaled_X = X_scaler.transform(X)\n",
    "\n",
    "# # Define the labels vector\n",
    "# y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "\n",
    "# # Split up data into randomized training and test sets\n",
    "# rand_state = np.random.randint(0, 100)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "# print('Using:',orient,'orientations',pix_per_cell,\n",
    "#     'pixels per cell and', cell_per_block,'cells per block')\n",
    "# print('Feature vector length:', len(X_train[0]))\n",
    "# # Use a linear SVC \n",
    "# svc = LinearSVC()\n",
    "# # Check the training time for the SVC\n",
    "# t=time.time()\n",
    "# svc.fit(X_train, y_train)\n",
    "# t2 = time.time()\n",
    "# print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "# # Check the score of the SVC\n",
    "# print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "# # Check the prediction time for a single sample\n",
    "# t=time.time()\n",
    "\n",
    "# image = mpimg.imread('bbox-example-image.jpg')\n",
    "# draw_image = np.copy(image)\n",
    "\n",
    "# # Uncomment the following line if you extracted training\n",
    "# # data from .png images (scaled 0 to 1 by mpimg) and the\n",
    "# # image you are searching is a .jpg (scaled 0 to 255)\n",
    "# #image = image.astype(np.float32)/255\n",
    "\n",
    "# windows = slide_window(image, x_start_stop=[None, None], y_start_stop=y_start_stop, \n",
    "#                     xy_window=(96, 96), xy_overlap=(0.5, 0.5))\n",
    "\n",
    "# hot_windows = search_windows(image, windows, svc, X_scaler, color_space=color_space, \n",
    "#                         spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "#                         orient=orient, pix_per_cell=pix_per_cell, \n",
    "#                         cell_per_block=cell_per_block, \n",
    "#                         hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "#                         hist_feat=hist_feat, hog_feat=hog_feat)                       \n",
    "\n",
    "# window_img = draw_boxes(draw_image, hot_windows, color=(0, 0, 255), thick=6)                    \n",
    "\n",
    "# plt.imshow(window_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def plot_gradient_thresholds(fname):\n",
    "#     image = mpimg.imread(fname)\n",
    "#     undistorted_example_image = undistort(image, mtx, dist)\n",
    "#     threshold = (180, 255)\n",
    "#     gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "#     abs_sobel_x = abs_sobel_threshold(image, 'x', 3, (50, 100))\n",
    "#     abs_sobel_y = abs_sobel_threshold(image, 'y', 3, (50, 100))\n",
    "#     magnitude_sobel = magnitude_threshold(image, 9, (30, 100))\n",
    "#     direction_sobel = direction_threshold(image, 17, (0.7, 1.3))\n",
    "#     binary_gray = np.zeros_like(gray)\n",
    "#     binary_gray[(gray > threshold[0]) & (gray <= threshold[1])] = 1\n",
    "#     combined = np.zeros_like(direction_sobel)\n",
    "#     combined[((abs_sobel_x == 1) & (abs_sobel_y == 1)) | ((magnitude_sobel == 1) & (direction_sobel == 1))] = 1\n",
    "\n",
    "#     # Plotting thresholded images\n",
    "#     f, axs = plt.subplots(3, 3, figsize=(20,10))\n",
    "#     axs = axs.ravel()\n",
    "    \n",
    "#     axs[0].set_title(fname)\n",
    "#     axs[0].imshow(image)\n",
    "\n",
    "#     axs[1].set_title('Gradient -- x-oriented')\n",
    "#     axs[1].imshow(abs_sobel_x, cmap='gray')\n",
    "\n",
    "#     axs[2].set_title('Gradient -- y-oriented')\n",
    "#     axs[2].imshow(abs_sobel_y, cmap='gray')\n",
    "\n",
    "#     axs[3].set_title(fname)\n",
    "#     axs[3].imshow(image)\n",
    "\n",
    "#     axs[4].set_title('Magnitude Threshold')\n",
    "#     axs[4].imshow(magnitude_sobel, cmap='gray')\n",
    "\n",
    "#     axs[5].set_title('Direction Threshold')\n",
    "#     axs[5].imshow(direction_sobel, cmap='gray')\n",
    "\n",
    "#     axs[6].set_title(fname)\n",
    "#     axs[6].imshow(image)\n",
    "    \n",
    "#     axs[7].set_title('Gray Thresholded')\n",
    "#     axs[7].imshow(binary_gray, cmap='gray')\n",
    "\n",
    "#     axs[8].set_title('Combined Magnitude and Direction Gradient')\n",
    "#     axs[8].imshow(combined, cmap='gray')\n",
    "    \n",
    "# def plot_converted_color_space_thresholds(fname, flag): \n",
    "#     image = mpimg.imread(fname)\n",
    "#     undistorted_example_image = undistort(image, mtx, dist)\n",
    "    \n",
    "#     threshold = (90, 255)\n",
    "#     converted_color_space = cv2.cvtColor(image, flag)\n",
    "#     channel_1 = converted_color_space[:, :, 0]\n",
    "#     channel_2 = converted_color_space[:, :, 1]\n",
    "#     channel_3 = converted_color_space[:, :, 2]\n",
    "    \n",
    "#     binary_1 = np.zeros_like(channel_1)\n",
    "#     binary_2 = np.zeros_like(channel_2)\n",
    "#     binary_3 = np.zeros_like(channel_3)\n",
    "    \n",
    "#     binary_1[(channel_1 > threshold[0]) & (channel_1 <= threshold[1])] = 1\n",
    "#     binary_2[(channel_2 > threshold[0]) & (channel_2 <= threshold[1])] = 1\n",
    "#     binary_3[(channel_3 > threshold[0]) & (channel_3 <= threshold[1])] = 1\n",
    "    \n",
    "#     f, axs = plt.subplots(2, 4, figsize=(20, 10))\n",
    "#     axs = axs.ravel()\n",
    "    \n",
    "#     axs[0].set_title(fname)\n",
    "#     axs[0].imshow(image)\n",
    "    \n",
    "#     axs[1].set_title('1')\n",
    "#     axs[1].imshow(channel_1)\n",
    "    \n",
    "#     axs[2].set_title('2')\n",
    "#     axs[2].imshow(channel_2)\n",
    "    \n",
    "#     axs[3].set_title('3')\n",
    "#     axs[3].imshow(channel_3)\n",
    "    \n",
    "#     axs[4].set_title(fname)\n",
    "#     axs[4].imshow(image)\n",
    "    \n",
    "#     axs[5].set_title('Channel 1 Threshold')\n",
    "#     axs[5].imshow(binary_1, cmap='gray')\n",
    "    \n",
    "#     axs[6].set_title('Channel 2 Threshold')\n",
    "#     axs[6].imshow(binary_2, cmap='gray')\n",
    "    \n",
    "#     axs[7].set_title('Channel 3 Threshold')\n",
    "#     axs[7].imshow(binary_3, cmap='gray')\n",
    "    \n",
    "# def plot_combined_thresholds(image, orientation, sobel_threshold, sobel_kernel, flag, c, color_threshold):\n",
    "#     undistorted_example_image = undistort(image)\n",
    "    \n",
    "#     if orientation == 'x' or orientation == 'y': \n",
    "#         sobel_binary = abs_sobel_threshold(undistorted_example_image, orientation, sobel_kernel, sobel_threshold)\n",
    "#     elif orientation == 'm': \n",
    "#         sobel_binary = magnitude_threshold(undistorted_example_image, sobel_kernel, sobel_threshold)\n",
    "#     elif orientation == 'd': \n",
    "#         sobel_binary = direction_threshold(undistorted_example_image, sobel_kernel, sobel_threshold)\n",
    "#     elif orientation == \"md\": \n",
    "#         sobel_binary_magnitude = magnitude_threshold(undistorted_example_image, sobel_kernel, sobel_threshold)\n",
    "#         sobel_binary_direction = magnitude_threshold(undistorted_example_image, sobel_kernel, sobel_threshold)        \n",
    "        \n",
    "#     # Threshold color channel\n",
    "#     converted_color_space_image = cv2.cvtColor(undistorted_example_image, flag)\n",
    "#     channel = converted_color_space_image[:, :, c]\n",
    "#     channel_binary = np.zeros_like(channel)\n",
    "#     channel_binary[(channel >= color_threshold[0]) & (channel <= color_threshold[1])] = 1\n",
    "\n",
    "#     # Stack each channel to view their individual contributions in green and blue respectively\n",
    "#     # This returns a stack of the two binary images, whose components you can see as different colors\n",
    "#     color_binary = np.dstack(( np.zeros_like(sobel_binary), sobel_binary, channel_binary))\n",
    "\n",
    "#     # Combine the two binary thresholds\n",
    "#     combined_binary = np.zeros_like(sobel_binary)\n",
    "#     combined_binary[(sobel_binary == 1) | (channel_binary == 1)] = 1\n",
    "\n",
    "#     # Plotting thresholded images\n",
    "#     f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "#     ax1.set_title('Stacked thresholds')\n",
    "#     ax1.imshow(color_binary)\n",
    "\n",
    "#     ax2.set_title('Gradient: ' + orientation + '--' + 'Color Space: ' + str(flag) + '--' + 'Color Channel: ' + str(c))\n",
    "#     ax2.imshow(combined_binary, cmap='gray')\n",
    "    \n",
    "# def get_combined_thresholded_image(fname, orientation, sobel_threshold, sobel_kernel, flag, c, color_threshold):\n",
    "#     image = mpimg.imread(fname)\n",
    "#     undistorted_example_image = undistort(image)\n",
    "    \n",
    "#     if orientation == 'x' or orientation == 'y': \n",
    "#         sobel_binary = abs_sobel_threshold(undistorted_example_image, orientation, sobel_kernel, sobel_threshold)\n",
    "#     elif orientation == 'm': \n",
    "#         sobel_binary = magnitude_threshold(undistorted_example_image, sobel_kernel, sobel_threshold)\n",
    "#     elif orientation == 'd': \n",
    "#         sobel_binary = direction_threshold(undistorted_example_image, sobel_kernel, sobel_threshold)\n",
    "#     elif orientation == \"md\": \n",
    "#         sobel_binary_magnitude = magnitude_threshold(undistorted_example_image, sobel_kernel, sobel_threshold)\n",
    "#         sobel_binary_direction = magnitude_threshold(undistorted_example_image, sobel_kernel, sobel_threshold)        \n",
    "        \n",
    "#     # Threshold color channel\n",
    "#     converted_color_space_image = cv2.cvtColor(undistorted_example_image, flag)\n",
    "#     channel = converted_color_space_image[:, :, c]\n",
    "#     channel_binary = np.zeros_like(channel)\n",
    "#     channel_binary[(channel >= color_threshold[0]) & (channel <= color_threshold[1])] = 1\n",
    "\n",
    "#     # Stack each channel to view their individual contributions in green and blue respectively\n",
    "#     # This returns a stack of the two binary images, whose components you can see as different colors\n",
    "#     color_binary = np.dstack(( np.zeros_like(sobel_binary), sobel_binary, channel_binary))\n",
    "\n",
    "#     # Combine the two binary thresholds\n",
    "#     combined_binary = np.zeros_like(sobel_binary)\n",
    "#     combined_binary[(sobel_binary == 1) | (channel_binary == 1)] = 1\n",
    "\n",
    "#     return combined_binary\n",
    "\n",
    "# def plot_hsv_mask(image, y_threshold_min, y_threshold_max, w_threshold_min, w_threshold_max):\n",
    "#     hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "#     yellow_lower_bound = np.array(y_threshold_min)\n",
    "#     yellow_upper_bound = np.array(y_threshold_max)\n",
    "#     white_lower_bound = np.array(w_threshold_min)\n",
    "#     white_upper_bound = np.array(w_threshold_max)\n",
    "    \n",
    "#     yellow_mask = cv2.inRange(hsv, yellow_lower_bound, yellow_upper_bound)\n",
    "#     white_mask = cv2.inRange(hsv, white_lower_bound, white_upper_bound)\n",
    "# #     res = cv2.bitwise_or(yellow_mask, white_mask)\n",
    "#     res = cv2.bitwise_and(image, image, mask=white_mask)\n",
    "    \n",
    "#         # Plotting thresholded images\n",
    "#     f, axis = plt.subplots(1, 1, figsize=(10,10))\n",
    "#     axis.set_title('Stacked thresholds')\n",
    "#     axis.imshow(res)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def region_of_interest(img, vertices):\n",
    "#     \"\"\"\n",
    "#     Applies an image mask.\n",
    "    \n",
    "#     Only keeps the region of the image defined by the polygon\n",
    "#     formed from `vertices`. The rest of the image is set to black.\n",
    "#     \"\"\"\n",
    "#     #defining a blank mask to start with\n",
    "#     mask = np.zeros_like(img)   \n",
    "    \n",
    "#     #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "#     if len(img.shape) > 2:\n",
    "#         channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "#         ignore_mask_color = (255,) * channel_count\n",
    "#     else:\n",
    "#         ignore_mask_color = 255\n",
    "        \n",
    "#     #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "#     cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "#     #returning the image only where mask pixels are nonzero\n",
    "#     masked_image = cv2.bitwise_and(img, mask)\n",
    "#     return masked_image\n",
    "\n",
    "\n",
    "    \n",
    "# def color_mask(c_space, low, high):\n",
    "#     mask = cv2.inRange(c_space, low, high)\n",
    "#     return mask\n",
    "\n",
    "# def apply_color_mask(image, mask):\n",
    "#     res = cv2.bitwise_and(image, image, mask=mask)\n",
    "#     return res\n",
    "\n",
    "# def apply_color_mask2(hsv,img,low,high):\n",
    "#     # Apply color mask to image\n",
    "#     mask = cv2.inRange(hsv, low, high)\n",
    "#     res = cv2.bitwise_and(img,img, mask= mask)\n",
    "#     return res\n",
    "\n",
    "# def apply_combined_mask(mask_1, mask_2): \n",
    "#     combined_mask = cv2.bitwise_xor(mask_1, mask_2)\n",
    "#     return combined_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_windows(img, windows, clf, scaler, color_space='RGB', \n",
    "                    spatial_size=(32, 32), hist_bins=32, \n",
    "                    hist_range=(0, 256), orient=9, \n",
    "                    pix_per_cell=8, cell_per_block=2, \n",
    "                    hog_channel=0, spatial_feat=True, \n",
    "                    hist_feat=True, hog_feat=True):\n",
    "\n",
    "    #1) Create an empty list to receive positive detection windows\n",
    "    on_windows = []\n",
    "    #2) Iterate over all windows in the list\n",
    "    for window in windows:\n",
    "        #3) Extract the test window from original image\n",
    "        test_img = cv2.resize(img[window[0][1]:window[1][1], window[0][0]:window[1][0]], (64, 64))      \n",
    "        #4) Extract features for that window using single_img_features()\n",
    "        features = single_img_features(test_img, color_space=color_space, \n",
    "                            spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                            orient=orient, pix_per_cell=pix_per_cell, \n",
    "                            cell_per_block=cell_per_block, \n",
    "                            hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                            hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "        #5) Scale extracted features to be fed to classifier\n",
    "        test_features = scaler.transform(np.array(features).reshape(1, -1))\n",
    "        #6) Predict using your classifier\n",
    "        prediction = clf.predict(test_features)\n",
    "        #7) If positive (prediction == 1) then save the window\n",
    "        if prediction == 1:\n",
    "            on_windows.append(window)\n",
    "    #8) Return windows for positive detections\n",
    "    return on_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slide_window(img, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                    xy_window=(64, 64), xy_overlap=(0.5, 0.5)):\n",
    "    # If x and/or y start/stop positions not defined, set to image size\n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "    if y_start_stop[0] == None:\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] == None:\n",
    "        y_start_stop[1] = img.shape[0]\n",
    "    # Compute the span of the region to be searched    \n",
    "    xspan = x_start_stop[1] - x_start_stop[0]\n",
    "    yspan = y_start_stop[1] - y_start_stop[0]\n",
    "    # Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "    # Compute the number of windows in x/y\n",
    "    nx_buffer = np.int(xy_window[0]*(xy_overlap[0]))\n",
    "    ny_buffer = np.int(xy_window[1]*(xy_overlap[1]))\n",
    "    nx_windows = np.int((xspan-nx_buffer)/nx_pix_per_step) \n",
    "    ny_windows = np.int((yspan-ny_buffer)/ny_pix_per_step) \n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    # Loop through finding x and y window positions\n",
    "    # Note: you could vectorize this step, but in practice\n",
    "    # you'll be considering windows one by one with your\n",
    "    # classifier, so looping makes sense\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            # Calculate window position\n",
    "            startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "            endx = startx + xy_window[0]\n",
    "            starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "            endy = starty + xy_window[1]\n",
    "            \n",
    "            # Append window position to list\n",
    "            window_list.append(((startx, starty), (endx, endy)))\n",
    "    # Return the list of windows\n",
    "    return window_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#         # apply color conversion if other than 'RGB'\n",
    "#         if color_space != 'RGB':\n",
    "#             if color_space == 'HSV':\n",
    "#                 feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "#             elif color_space == 'LUV':\n",
    "#                 feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "#             elif color_space == 'HLS':\n",
    "#                 feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "#             elif color_space == 'YUV':\n",
    "#                 feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "#             elif color_space == 'YCrCb':\n",
    "#                 feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "#         else: feature_image = np.copy(image)      \n",
    "\n",
    "#         if spatial_feat == True:\n",
    "#             spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "#             file_features.append(spatial_features)\n",
    "            \n",
    "#         if hist_feat == True:\n",
    "#             # Apply color_hist()\n",
    "#             hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "#             file_features.append(hist_features)\n",
    "            \n",
    "#         if hog_feat == True:\n",
    "#         # Call get_hog_features() with vis=False, feature_vec=True\n",
    "#             if hog_channel == 'ALL':\n",
    "#                 hog_features = []\n",
    "#                 for channel in range(feature_image.shape[2]):\n",
    "#                     hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
    "#                                         orient, pix_per_cell, cell_per_block, \n",
    "#                                         vis=False, feature_vec=True))\n",
    "#                 hog_features = np.ravel(hog_features)        \n",
    "#             else:\n",
    "#                 hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "#                             pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "#             # Append the new feature vector to the features list\n",
    "#             file_features.append(hog_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lane Finding Method: Peaks in a Histogram & Sliding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def poly_fit_sliding_window(in_image): \n",
    "    # Take the histogram of the bottom half of the image\n",
    "    histogram = np.sum(in_image[in_image.shape[0]//2:, :], axis=0)\n",
    "    \n",
    "    out_image = np.dstack((in_image, in_image, in_image)) * 255\n",
    "\n",
    "    # Find the peak of the left ad right halves of the histogram\n",
    "    # These are the starting points for left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    left_x_base = np.argmax(histogram[:midpoint])\n",
    "    right_x_base = np.argmax(histogram[midpoint:midpoint+200]) + midpoint\n",
    "    \n",
    "    # Number of sliding windows\n",
    "    n_sliding_windows = 9\n",
    "\n",
    "    # Set the height of the windows\n",
    "    window_height = np.int(in_image.shape[0] / n_sliding_windows)\n",
    "\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = in_image.nonzero()\n",
    "    nonzero_y = np.array(nonzero[0])\n",
    "    nonzero_x = np.array(nonzero[1])\n",
    "\n",
    "    # Current positions to be updated for each window\n",
    "    left_x_current = left_x_base\n",
    "    right_x_current = right_x_base\n",
    "\n",
    "    # Width of windows +/- margin\n",
    "    margin = 100\n",
    "\n",
    "    # Minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_indices = []\n",
    "    right_lane_indices = []\n",
    "\n",
    "    # Step through windows one by one\n",
    "    for window in range(n_sliding_windows): \n",
    "        # Identify window boundaries in x and y (for both left and right)\n",
    "        window_y_low = in_image.shape[0] - (window + 1) * window_height\n",
    "        window_y_high = in_image.shape[0] - window * window_height\n",
    "        window_x_left_low = left_x_current - margin\n",
    "        window_x_left_high = left_x_current + margin\n",
    "        window_x_right_low = right_x_current - margin\n",
    "        window_x_right_high = right_x_current + margin\n",
    "\n",
    "        # Draw the windows on the visualization\n",
    "        cv2.rectangle(out_image, (window_x_left_low, window_y_low), (window_x_left_high, window_y_high), (0, 255, 0), 2)\n",
    "        cv2.rectangle(out_image, (window_x_right_low, window_y_low), (window_x_right_high, window_y_high), (0, 255, 0), 2)\n",
    "\n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_indices = ((nonzero_y >= window_y_low) & (nonzero_y < window_y_high) & \n",
    "                             (nonzero_x >= window_x_left_low) & (nonzero_x < window_x_left_high)).nonzero()[0]\n",
    "        good_right_indices = ((nonzero_y > window_y_low) & (nonzero_y < window_y_high) &\n",
    "                             (nonzero_x >= window_x_right_low) & (nonzero_x < window_x_right_high)).nonzero()[0]\n",
    "\n",
    "        # Append these indices to the lists\n",
    "        left_lane_indices.append(good_left_indices)\n",
    "        right_lane_indices.append(good_right_indices)\n",
    "\n",
    "        # If you found > minpix pixels, recenter the next window on their mean position\n",
    "        if len(good_left_indices) > minpix: \n",
    "            left_x_current = np.int(np.mean(nonzero_x[good_left_indices]))\n",
    "\n",
    "        if len(good_right_indices) > minpix: \n",
    "            right_x_current = np.int(np.mean(nonzero_x[good_right_indices]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_indices = np.concatenate(left_lane_indices)\n",
    "    right_lane_indices = np.concatenate(right_lane_indices)\n",
    "\n",
    "    # Extract left and right pixel positions\n",
    "    left_x = nonzero_x[left_lane_indices]\n",
    "    left_y = nonzero_y[left_lane_indices]\n",
    "    right_x = nonzero_x[right_lane_indices]\n",
    "    right_y = nonzero_y[right_lane_indices]\n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_line_fit, right_line_fit = (None, None)\n",
    "    if len(left_x) != 0: \n",
    "        left_line_fit = np.polyfit(left_y, left_x, 2)\n",
    "    else: \n",
    "        print (\"Left x DNE\")\n",
    "    \n",
    "    if len(right_x) != 0:\n",
    "        right_line_fit = np.polyfit(right_y, right_x, 2)\n",
    "    else: \n",
    "        print (\"Right x DNE\")\n",
    "        \n",
    "    # return out_image, histogram, left_line_fit, right_line_fit, left_lane_indices, right_lane_indices, nonzero_x, nonzero_y \n",
    "    return left_line_fit, right_line_fit, left_lane_indices, right_lane_indices, (out_image, histogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding Window Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for image_data in warped_and_thresholded:\n",
    "#     binary_warped = image_data[3]\n",
    "#     left_line_fit, right_line_fit, left_lane_indices, right_lane_indices, plot_components = poly_fit_sliding_window(binary_warped)\n",
    "#     plot_y = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0])\n",
    "#     left_fit_x = left_line_fit[0]*plot_y**2 + left_line_fit[1]*plot_y + left_line_fit[2]\n",
    "#     right_fit_x = right_line_fit[0]*plot_y**2 + right_line_fit[1]*plot_y + right_line_fit[2]\n",
    "\n",
    "#     plot_components[0][nonzero_y[left_lane_indices], nonzero_x[left_lane_indices]] = [255, 0, 0]\n",
    "#     plot_components[0][nonzero_y[right_lane_indices], nonzero_x[right_lane_indices]] = [0, 0, 255]\n",
    "    \n",
    "#     f, axis = plt.subplots(1, 1, figsize=(10, 10))\n",
    "#     axis.imshow(out_image)\n",
    "#     axis.plot(left_fit_x, plot_y, color='y')\n",
    "#     axis.plot(right_fit_x, plot_y, color='y')\n",
    "#     axis.set_xlim(0, 1280)\n",
    "#     axis.set_ylim(720, 0)# Next frame represented by new binary_warped \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example next frame visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def poly_fit_on_next_frame(binary_warped, previous_left_line_fit, previous_right_line_fit):\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzero_y = np.array(nonzero[0])\n",
    "    nonzero_x = np.array(nonzero[1])\n",
    "    margin = 100\n",
    "\n",
    "    left_lane_indices = ((nonzero_x > (previous_left_line_fit[0]*(nonzero_y**2) + previous_left_line_fit[1]*nonzero_y + \n",
    "                                       previous_left_line_fit[2] - margin)) & (nonzero_x < (previous_left_line_fit[0]*(nonzero_y**2) +\n",
    "                                       previous_left_line_fit[1]*nonzero_y + previous_left_line_fit[2] + margin)))\n",
    "\n",
    "    right_lane_indices = ((nonzero_x > (previous_right_line_fit[0]*(nonzero_y**2) + previous_right_line_fit[1]*nonzero_y + \n",
    "                                       previous_right_line_fit[2] - margin)) & (nonzero_x < (previous_right_line_fit[0]*(nonzero_y**2) +\n",
    "                                       previous_right_line_fit[1]*nonzero_y + previous_right_line_fit[2] + margin)))\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    left_x = nonzero_x[left_lane_indices]\n",
    "    left_y = nonzero_y[left_lane_indices]\n",
    "    right_x = nonzero_x[right_lane_indices]\n",
    "    right_y = nonzero_y[right_lane_indices]\n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_line_fit = np.polyfit(left_y, left_x, 2)\n",
    "    right_line_fit = np.polyfit(right_y, right_x, 2)\n",
    "    \n",
    "    return left_line_fit, right_line_fit, left_lane_indices, right_lane_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding Window Optimization for Next Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for image_data in warped_and_thresholded:\n",
    "#     binary_warped = image_data[3]\n",
    "#     # Create an image to draw on and an image to show the selection window\n",
    "#     out_image = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "#     window_image = np.zeros_like(out_image)\n",
    "\n",
    "#     # Color in left and right line pixels\n",
    "#     out_image[nonzero_y[left_lane_indices], nonzero_x[left_lane_indices]] = (255, 0, 0)\n",
    "#     out_image[nonzero_y[right_lane_indices], nonzero_x[right_lane_indices]] = (0, 0, 255)\n",
    "\n",
    "#     # Generate a polygon to illustrate the search window area\n",
    "#     # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "#     left_line_window_1 = np.array([np.transpose(np.vstack([left_fit_x - margin, plot_y]))])\n",
    "#     left_line_window_2 = np.array([np.flipud(np.transpose(np.vstack([left_fit_x + margin, plot_y])))])\n",
    "#     left_line_points = np.hstack((left_line_window_1, left_line_window_2))\n",
    "\n",
    "#     right_line_window_1 = np.array([np.transpose(np.vstack([right_fit_x - margin, plot_y]))])\n",
    "#     right_line_window_2 = np.array([np.flipud(np.transpose(np.vstack([right_fit_x + margin, plot_y])))])\n",
    "#     right_line_points = np.hstack((right_line_window_1, right_line_window_2))\n",
    "\n",
    "#     # Draw the lane onto the warped blank image\n",
    "#     cv2.fillPoly(window_image, np.int_([left_line_points]), (0, 255, 0))\n",
    "#     cv2.fillPoly(window_image, np.int_([right_line_points]), (0, 255, 0))\n",
    "#     result = cv2.addWeighted(out_image, 1, window_image, 0.3, 0)\n",
    "\n",
    "#     f, axis = plt.subplots(1, 1, figsize=(10, 10))\n",
    "#     axis.imshow(result)\n",
    "#     axis.plot(left_fit_x, plot_y, color='y')\n",
    "#     axis.plot(right_fit_x, plot_y, color='y')\n",
    "#     axis.set_xlim(0, 1280)\n",
    "#     axis.set_ylim(720, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# window_width = 25\n",
    "# window_height = 80\n",
    "# curve_centers = tracker(Mywindow_width = window_width, Mywindow_height = window_height, Mymargin = 25, My_ym = 10/720, My_xm = 4/384, Mysmooth_factor = 15)\n",
    "# window_centroids = curve_centers.find_window_centroids(warped)\n",
    "\n",
    "# l_points = np.zeros_like(warped)\n",
    "# r_points = np.zeros_like(warped)\n",
    "\n",
    "# left_x = []\n",
    "# right_x = []  \n",
    "\n",
    "# for level in range(0, len(window_centroids)):\n",
    "#     left_x.append(window_centroids[level][0])\n",
    "#     right_x.append(window_centoids[level][1])\n",
    "    \n",
    "#     l_mask = window_mask(window_width, window_height, warped, window_centroids[level][0], level)\n",
    "#     r_mask = window_mask(window_width, window_height, warped, window_centroids[level][1], level)\n",
    "    \n",
    "#     l_points[(l_points == 255) | ((l_mask == 1))] = 255\n",
    "#     r_points[(r_points == 255) | ((r_mask == 1))] = 255\n",
    "    \n",
    "    \n",
    "# yvals = range(0, warped.shape[0])\n",
    "# res_yvals = np.arange((warped.shape[0] - (window_height) / 2), 0, -window_height)\n",
    "\n",
    "# left_fit = np.polyfit(res_yvals, left_x, 2)\n",
    "# left_fit_x = left_fit[0]*yvals**2 + left_fit[1]*yvals + left_fit[2]\n",
    "# left_fit_x = np.array(left_fitx, np.int32)\n",
    "\n",
    "# right_fit = np.polyfit(res_yvals, right_x, 2)\n",
    "# right_fit_x = right_fit[0]*yvals**2 + right_fit[1]*yvals + right_fit[2]\n",
    "# right_fit_x = np.array(right_fitx, np.int32)\n",
    "\n",
    "# left_lane = np.array(List(zip(np.concatenate((left_fit_x-window_width/2, left_fit_x[::-1]+window_width/2), axis=0), np.concatenate((yvals, yvals[::-1]), axis=0) )), np.int32)\n",
    "# right_lane = np.array(List(zip(np.concatenate((right_fit_x-window_width/2, right_fit_x[::-1]+window_width/2), axis=0), np.concatenate((yvals, yvals[::-1]), axis=0) )), np.int32)\n",
    "# middle_marker = np.array(List(zip(np.concatenate((left_fit_x+window_width/2, right_fit_x[::-1]+window_width/2), axis=0), np.concatenate((yvals, yvals[::-1]), axis=0) )), np.int32)\n",
    "\n",
    "# road = np.zeros_like(img)\n",
    "# road_bkg = np.zeros_like(img)\n",
    "# cv2.fillPoly(road, [left_lane], color=[255, 0, 0])\n",
    "# cv2.fillPoly(road, [right_lane], color=[0, 0, 255])\n",
    "# cv2.fillPoly(road, [left_lane], color=[255, 255, 255])\n",
    "# cv2.fillPoly(road, [right_lane], color=[255, 255, 255])\n",
    "\n",
    "# road_warped = cv2.warpPerspective(road, Minv, img_size, flags=cv2.INTER_LINEAR)\n",
    "# road_warped_bkg = cv2.warpPerspective(road_bkg, Minv, img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "# base = cv2.addWeighted(img, 1.0, roard_warped_bkg, -1.0, 0.0)\n",
    "# result = cv2.addWeighted(base, 1.0, road_warpd, 1.0, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stores characteristics of each line detection\n",
    "# Create an instance for the left and right lanes\n",
    "class Line(): \n",
    "    def __init__(self): \n",
    "        # was the line detected in the last iteration\n",
    "        self.detected = False\n",
    "        \n",
    "        # x values of the last n fits of line\n",
    "        self.recent_xfitted = [] \n",
    "        \n",
    "        # average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None\n",
    "        \n",
    "        # polynomial coefficients averaged over last n iterations\n",
    "        self.best_fit = None\n",
    "        \n",
    "        # polynomial coefficients for the most recent fit\n",
    "        self.current_fit = []\n",
    "        \n",
    "        # radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None\n",
    "        \n",
    "        # distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None\n",
    "        \n",
    "        # difference in fit coefficients between last and new fits\n",
    "        self.coefficient_diffs = np.array([0, 0, 0], dtype='float')\n",
    "        \n",
    "        self.px_count = None\n",
    "        \n",
    "    # COME BACK TO FIX THIS AND MODIFY\n",
    "    def add_fit(self, fit, inds):\n",
    "        # add a found fit to the line, up to n\n",
    "        if fit is not None:\n",
    "            if self.best_fit is not None:\n",
    "                # if we have a best fit, see how this new fit compares\n",
    "                self.coefficient_diffs = abs(fit-self.best_fit)\n",
    "            if (self.coefficient_diffs[0] > 0.001 or \\\n",
    "               self.coefficient_diffs[1] > 1.0 or \\\n",
    "               self.coefficient_diffs[2] > 100.) and \\\n",
    "               len(self.current_fit) > 0:\n",
    "                # bad fit! abort! abort! ... well, unless there are no fits in the current_fit queue, then we'll take it\n",
    "                self.detected = False\n",
    "            else:\n",
    "                self.detected = True\n",
    "                self.px_count = np.count_nonzero(inds)\n",
    "                self.current_fit.append(fit)\n",
    "#                 print (\"Appending current fit\")\n",
    "#                 print (\"After appending new current fit: \", self.current_fit)\n",
    "                if len(self.current_fit) > 5:\n",
    "                    # throw out old fits, keep newest n\n",
    "                    self.current_fit = self.current_fit[len(self.current_fit)-5:]\n",
    "                self.best_fit = np.average(self.current_fit, axis=0)\n",
    "        # or remove one from the history, if not found\n",
    "        else:\n",
    "            self.detected = False\n",
    "            if len(self.current_fit) > 0:\n",
    "#                 print (\"Length of current fit is greater than 0\")\n",
    "                # throw out oldest fit\n",
    "                self.current_fit = self.current_fit[:len(self.current_fit)-1]\n",
    "#                 print (self.current_fit)\n",
    "            if len(self.current_fit) > 0:\n",
    "#                 print (\"Length of current fit is still greater than 0 after trimming fat\")\n",
    "                # if there are still any fits in the queue, best_fit is their average\n",
    "                self.best_fit = np.average(self.current_fit, axis=0)\n",
    "#                 print (self.best_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipeline(image): \n",
    "    # 1. Process the image (undistort, thresholding, perspective transform)\n",
    "    undistorted, thresholded, warped_image, M, Minv = process_image(image)\n",
    "    \n",
    "    # 2. Identify lane lines \n",
    "    if not left_line.detected and not right_line.detected: \n",
    "        # Use sliding window\n",
    "        left_line_fit, right_line_fit, left_lane_indices, right_lane_indices, extra = poly_fit_sliding_window(warped_image)\n",
    "    else: \n",
    "        left_line_fit, right_line_fit, left_lane_indices, right_lane_indices = poly_fit_on_next_frame(warped_image, left_line.best_fit, right_line.best_fit)\n",
    "        \n",
    "    # 3. Sanity-check the new lines\n",
    "    if left_line_fit is not None and right_line_fit is not None:\n",
    "        # We are defining lines in terms of f(y) because lanes are vertical\n",
    "        # y = np.linspace(0, image.shape[0]-1, image.shape[0])\n",
    "        y = image.shape[0]\n",
    "        # Measure radius of curvature / line effectiveness\n",
    "        left_fit_x = left_line_fit[0]*y**2 + left_line_fit[1]*y + left_line_fit[2]\n",
    "        right_fit_x = right_line_fit[0]*y**2 + right_line_fit[1]*y + right_line_fit[2]\n",
    "        diff = abs(left_fit_x - right_fit_x)\n",
    "        if abs(diff - 500) > 300:\n",
    "            left_line_fit = None\n",
    "            right_line_fit = None\n",
    "            \n",
    "    # 4. Add the new lines assuming they are reasonable\n",
    "    left_line.add_fit(left_line_fit, left_lane_indices)\n",
    "    right_line.add_fit(right_line_fit, right_lane_indices)\n",
    "            \n",
    "    # 5. Draw lane lines back onto original image\n",
    "    left_line_curvature, right_line_curvature = radius_of_curvature(warped_image, left_lane_indices, right_lane_indices)\n",
    "    distance = distance_from_center(warped_image, left_line_fit, right_line_fit)\n",
    "    \n",
    "    # 5. Return updated image\n",
    "    left_best_fit = left_line.best_fit\n",
    "    right_best_fit = right_line.best_fit\n",
    "    if left_line.best_fit is not None and right_line.best_fit is not None: \n",
    "        updated_image_with_lanes = draw_lanes(undistorted, warped_image, Minv, left_best_fit, right_best_fit)\n",
    "        left_rad, right_rad = radius_of_curvature(warped_image, left_lane_indices, right_lane_indices)\n",
    "        center_distance = distance_from_center(warped_image, left_best_fit, right_best_fit)\n",
    "        updated_image_with_lanes_and_data = draw_data(updated_image_with_lanes, (left_rad + right_rad)/2, center_distance)\n",
    "    else: \n",
    "        updated_image_with_lanes_and_data = image\n",
    "        \n",
    "    return updated_image_with_lanes_and_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
